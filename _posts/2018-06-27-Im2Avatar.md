---
title: Im2Avatar\: Colorful 3D Reconstruction from a Single Image
description: Paper Summary
header: Im2Avatar\: Colorful 3D Reconstruction from a Single Image
duration: 5 minutes read
categories: blog
---

(Arxiv paper)

## Objective

Perform single image reconstruction, in terms of both shape and color.

## Network

![Network](/blog_images/2018-06-27_11-08-42.png)



### Overview

* 2 encoder-decoder branches. 
  * Top branch: Predict the shape (in terms of occupied/unoccupied voxels)
  * Bottom branch: Predict the color. This branch has 2 subbranches. 1) Regress the color, 2) Predicts flow to "transfer colors" from the 2D image to 3D voxels, 3) Predict the weights between 1 & 2.
* There's a loss for each of the subbranches (i.e. 4 losses in total). Interestingly, the equations do not show any weighting between the individual losses.



### Branch 1: Shape Learning

Fairly standard. Encoder network learns a viewpoint invariant latent representation. This is then fed into a 3D deconvolutional network.

One novel contribution is the use of _Mean Squared False Cross-Entropy Loss (MSFCEL)_ instead of the more typical cross entropy or L2 loss. Essentially it is the weighted sum of the squared cross entropy computed on the unoccupied and occupied voxels separately. But I'm not very convinced of the utility of this cross-entropy loss.

### Branch 2: Surface Color Learning

As mentioned earlier, this has 3 sub-branches

#### Flow

This branch regresses 2 values representing the 2D pixel coordinates for each voxel. The groundtruth coordinates are obtained in 2 ways:

* For unoccluded voxels: From intrinsic/extrinsic matrices
* For occluded voxels: "first finding all the foreground 2D points in the view whose colors are similar to that of the considered 3D point, and then selecting the one closest to its projected 2D position via perspective projection". 
  To be frank, I find this groundtruth very weird.

The loss is then the L2 loss between the predicted and groundtruth flows. Note that the loss is only computed for surface  (i.e. occupied and non-interior) voxels.

#### Surface Color Regression

Regresses the 3 RGB values in the range (0, 1). Uses L2 loss between predicted and groundtruth colors.

#### Surface Color Blending

The third network predicts the weights between the two previous predicted colors. This uses the loss between its predicted blended color and the groundtruth color



### Results

Evaluated on ShapeNet and a "Colorful Human dataset" (constructed from [MakeHuman]). Looks fairly good.

![Qualitiative Results](/blog_images/2018-06-27_11-26-21.png)





[MakeHuman]: http://www.makehuman.org